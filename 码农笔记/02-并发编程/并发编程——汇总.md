# CPU
现代计算机用的冯诺依曼计算机模型：
五大核心组成部分：控制器、运算器、存储器、输入、输出

单核CPU架构

![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230810083611.png)

多核CPU架构
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230810082043.png)


CPU多核
一个多核的CPU也就是一个CPU上有多个处理器核心，这样有什么好处呢？比如说现在我们要在一台计算机上跑一个多线程的程序，因为是一个进程里的线程，所以需要一些共享一些存储变量，如果这台计算机都是单核单线程CPU的话（有多个CPU），就意味着这个程序的不同线程需要经常在CPU之间的外部总线上通信，同时还要处理<mark style="background: #FF5582A6;">不同CPU</mark>之间<mark style="background: #FF5582A6;">不同缓存</mark>导致数据不一致的问题，所以在这种场景下多核单CPU的架构就能发挥很大的优势，通信都在<mark style="background: #FF5582A6;">内部总线</mark>，共用<mark style="background: #FF5582A6;">同一个缓存</mark>。

多CPU架构：
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230810085108.png)



CPU读取存储器数据过程
CPU要取寄存器XX的值，只需要一步：直接读取。
CPU要取L1 cache的某个值，需要1-3步（或者更多）：把cache行锁住，把某个数据拿
来，解锁，如果没锁住就慢了。
CPU要取L2 cache的某个值，先要到L1 cache里取，L1当中不存在，在L2里，L2开始加锁，加锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁。
CPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU。
CPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，
等待回应，回应数据保存到L3（如果没有就到L2），再从L3/2到L1，再从L1到CPU，之后解除总线锁定。

多线程环境下存在的问题
缓存一致性问题




# 线程

## Java线程的6种状态
新建NEW
<mark style="background: #FF5582A6;">RUNNABLE</mark>：（包括了传统操作系统线程的<mark style="background: #FF5582A6;">就绪ready和运行running两个状态</mark>）
阻塞BLOCKED：等待锁的释放
等待WAITING：调用了wait等方法，释放锁，进入等待状态，需要其他线程唤醒
TIMED_WAITING：超时等待状态。线程等待一个具体的时间，时间到后会被自动唤醒
TERMINATED： 终止状态。此时线程已执行完毕
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230808180546.png)



# 并发带来的问题
## 安全性问题：
	1.原子性 （都做，或者都不做，即不会被线程调度机制打断的操作，没有上下文切换）
	2.可见性 
	3.有序性


```java
i = 0; // 操作1 对基本数据类型变量的赋值是原子操作；
i++;   // 操作2 包含三个操作，读取i的值，将i加1，将值赋给i；
i = j; // 操作3 读取j的值，将j的值赋给i；
i = i + 1; // 操作4 包含三个操作，读取i的值，将i加1，将值赋给i；

//只有操作1是原子操作，234都不是原子操作
```



为了解决多线程<mark style="background: #FF5582A6;">可见性</mark>问题，Java语言提供了`volatile`这个关键字。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通共享变量不能保证可见性，因为变量被修改后什么时候刷回到主存是不确定的，另外一个线程读的可能就是旧值。

在Java语言中通过可以使用synchronize或者lock来保证<mark style="background: #FF5582A6;">原子性</mark>和<mark style="background: #FF5582A6;">可见性</mark>。
加锁可以保证在同一时刻只有一个线程在执行同步代码块，释放锁之前会将变量刷回至主存，这样也就保证了可见性

## 活跃性问题
死锁、活锁、饥饿问题

## 性能问题
多线程并发一定比单线程串行执行快吗，答案是不一定，因为多线程有<mark style="background: #D2B3FFA6;">创建线程</mark>和<mark style="background: #D2B3FFA6;">线程上下文切换</mark>的开销

创建线程是直接向系统申请资源的，对操作系统来说创建一个线程的代价是十分昂贵的，需要给它分配内存、列入调度等。

线程创建完之后，还会遇到线程`上下文切换`

一般减少上下文切换的方法有：

- 无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。
- <mark style="background: #FFB8EBA6;">CAS算法</mark>，利用Atomic下使用CAS算法来更新数据，使用了<mark style="background: #FFB8EBA6;">乐观锁</mark>，可以有效的减少一部分不必要的锁竞争带来的上下文切换
- 使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态
- 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换


# Java内存模型JMM
## JMM介绍
JMM不同和Java内存区域不一样
先谈运行时数据区，然后JMM


## JMM与Java内存区域划分的区别与联系

上面两小节分别提到了JMM和Java运行时内存区域的划分，这两者既有差别又有联系：
- 区别
    两者是不同的概念层次。JMM是抽象的，他是用来描述<mark style="background: #FF5582A6;">一组规则</mark>，通过这个规则来控制各个变量的访问方式，围绕**原子性、有序性、可见性**等展开的。而Java运行时内存的划分是具体的，是JVM运行Java程序时，必要的**内存划分**。
- 联系
    都存在私有数据区域和共享数据区域。一般来说，JMM中的主内存属于共享数据区域，他是包含了堆和方法区；同样，JMM中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。 


线程之间的<mark style="background: #D2B3FFA6;">共享变量</mark>存在<mark style="background: #D2B3FFA6;">主内存</mark>中，每个线程都有一个私有的<mark style="background: #D2B3FFA6;">本地内存</mark>，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等


根据JMM的规定，线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取

**JMM通过控制<mark style="background: #BBFABBA6;">主内存</mark>与每个线程的<mark style="background: #BBFABBA6;">本地内存</mark>之间的交互，来提供内存可见性保证**

Java中的volatile关键字可以保证多线程操作共享变量的<mark style="background: #FF5582A6;">可见性</mark>以及<mark style="background: #FF5582A6;">禁止指令重排序</mark>，synchronized关键字不仅保证<mark style="background: #D2B3FFA6;">可见性</mark>，同时也保证了<mark style="background: #FFB8EBA6;">原子性</mark>（互斥性）。

在更底层，JMM通过<mark style="background: #FFB8EBA6;">内存屏障</mark>来实现内存的<mark style="background: #BBFABBA6;">可见性以及禁止重排序</mark>。为了程序员的方便理解，提出了happens-before，它更加的简单易懂，从而避免了程序员为了理解内存可见性而去学习复杂的重排序规则以及这些规则的具体实现方法。


**指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致**。所以在多线程下，指令重排序可能会导致一些问题


# volatile 
## 原理
volatile 可以保证可见性，但不保证原子性：

- 当写一个 volatile 变量时，JMM 会把该线程本地内存中的变量强制刷新到主内存中去；
- 这个写操作会导致其他线程中的 volatile 变量缓存无效

重排序需要遵守一定规则：
- 重排序操作不会对<mark style="background: #FF5582A6;">存在数据依赖关系的操作</mark>进行重排序。比如：a=1;b=a; 这个指令序列，由于第二个操作依赖于第一个操作，所以在编译时和处理器运行时这两个操作不会被重排序。
- 重排序是为了优化性能，<mark style="background: #FF5582A6;">但是不管怎么重排序，单线程下程序的执行结果不能被改变</mark>。比如：a=1;b=2;c=a+b 这三个操作，第一步（a=1)和第二步(b=2)由于不存在数据依赖关系， 所以可能会发生重排序，但是 c=a+b 这个操作是不会被重排序的，因为需要保证最终的结果一定是 c=a+b=3。

使用 volatile 关键字修饰共享变量可以禁止这种重排序。若用 volatile 修饰共享变量，在编译时，会在指令序列中插入**内存屏障**来禁止特定类型的处理器重排序，volatile 禁止指令重排序也有一些规则：

- 当程序执行到 volatile 变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；
- 在进行指令优化时，不能将对 volatile 变量访问的语句放在其后面执行，也不能把 volatile 变量后面的语句放到其前面执行。

“也就是说，执行到 volatile 变量时，其前面的所有语句都执行完，后面所有语句都未执行。且前面语句的结果对 volatile 变量及其后面语句可见。”


## 单例模式DCL (double check lock) 要加volatile
instance = new TestInstance()可以分解成三个操作
```java
a.   memory = allocate() //分配内存
b.   ctorInstanc(memory) //初始化对象
c.   instance = memory   //设置instance指向刚分配的地址
```
上面的代码在编译运行时，可能会出现重排序从 a-b-c 排序为 a-c-b。在多线程的情况下会出现以下问题。
当线程 A 在执行第 5 行代码时，B 线程进来执行到第 2 行代码。假设此时 A 执行的过程中发生了指令重排序，即先执行了 a 和 c，没有执行 b。那么由于 A 线程执行了 c 导致 instance 指向了一段地址，所以 B 线程判断 instance 不为 null，会直接跳到第 6 行并返回一个未初始化的对象


volatile 可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在 JVM 底层 volatile 是采用“内存屏障”来实现的。

观察加入 volatile 关键字和没有加入 volatile 关键字时所生成的汇编代码发现，加入 volatile 关键字时，会多出一个 lock 前缀指令，lock 前缀指令实际上相当于一个内存屏障（也称内存栅栏），内存屏障会提供 3 个功能：

- 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
- 它会强制将对缓存的修改操作立即写入主存；
- 如果是写操作，它会导致其他 CPU 中对应的缓存行无效


Volatile关键字能够在并发条件下，强制将修改后的值刷新到主内存中来保持内存的<mark style="background: #FF5582A6;">可见性</mark>。通过 CPU<mark style="background: #FF5582A6;">内存屏障</mark>禁止编译器指令性重排来保证并发操作的<mark style="background: #FF5582A6;">有序性</mark>
volatile 只是保证读写具有原子性，但是对于 ++ 操作的<mark style="background: #D2B3FFA6;">复合操作</mark>是不存在原子操作的。只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，比如：**对变量的写操作不依赖于当前值。**

volatile 是不错的机制，但是 volatile 不能保证原子性。因此对于同步最终还是要回到锁机制上来。即悲观锁和乐观锁

独占锁是一种悲观锁，synchronized 就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是 CAS，Compare and Swap


# synchronized
volatile不能保证原子性，要保证原子性，用synchronized，Lock


synchronized 是可重入锁，一个线程调用 synchronized 方法的同时，在其方法体内部调用该对象另一个 synchronized 方法是允许的


Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。所以在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是：
1. 无锁状态
2. 偏向锁状态
3. 轻量级锁状态
4. 重量级锁状态

最开始一个new出一个对象，没有被上锁，<mark style="background: #FF5582A6;">无锁</mark>状态
当对象状态为<mark style="background: #FF5582A6;">偏向锁</mark>时，`Mark Word`存储的是偏向的<mark style="background: #FF5582A6;">线程ID</mark>；
当状态为<mark style="background: #FF5582A6;">轻量级锁</mark>时，`Mark Word`存储的是指向<mark style="background: #FF5582A6;">线程栈中`Lock Record`</mark>的指针；
当状态为<mark style="background: #FF5582A6;">重量级锁</mark>时，`Mark Word`为指向<mark style="background: #FF5582A6;">堆中的monitor对象</mark>的指针

![image.png](https://cdn.nlark.com/yuque/0/2023/png/663445/1682421546838-51ff3295-1b26-44d0-bc44-f9c4579aa0fe.png#averageHue=%2396bf7b&clientId=ubc4dc362-78ee-4&from=paste&height=369&id=u1d4038ee&originHeight=738&originWidth=1419&originalType=binary&ratio=2&rotation=0&showTitle=false&size=187474&status=done&style=none&taskId=u0f6334d7-185f-41bc-aa15-6397bfd4db9&title=&width=709.5)

## 偏向锁
Hotspot的作者经过以往的研究发现大多数情况下**锁不仅不存在多线程竞争，而且总是由同一线程多次获得**，于是引入了偏向锁。

偏向锁会偏向于<mark style="background: #FF5582A6;">第一个访问锁的线程</mark>，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。也就是说，**偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能。**

> 大白话就是对锁置个变量，如果发现为true，代表资源无竞争，则无需再走各种加锁/解锁流程。如果为false，代表存在其他线程竞争资源，那么就会走后面的流程。


一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的<mark style="background: #FF5582A6;">线程ID</mark>。当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己的线程ID。

如果是，表明该线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；
如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用<mark style="background: #FF5582A6;">CAS</mark>来替换Mark Word里面的线程ID为新线程的ID，这个时候要分两种情况：

- 成功，表示之前的线程不存在了， Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁；
- 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为<mark style="background: #FF5582A6;">轻量级锁</mark>，会按照轻量级锁的方式进行竞争锁。

## 轻量级锁
多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。

JVM会为每个线程在当前线程的栈帧中创建用于存储<mark style="background: #FF5582A6;">锁记录</mark>的空间，我们称为Displaced Mark Word。如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。

然后线程尝试用CAS将锁的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。

> 自旋：不断尝试去获取锁，一般用循环来实现。

自旋是需要<mark style="background: #FF5582A6;">消耗CPU</mark>的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，<mark style="background: #FF5582A6;">白白浪费CPU资源</mark>。解决这个问题最简单的办法就是指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。

但是JDK采用了更聪明的方式——<mark style="background: #FF5582A6;">适应性自旋</mark>，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。

自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会**升级成重量级锁**。

**轻量级锁的释放：**

在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。

一张图说明加锁和释放锁的过程：
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230809034451.png)


## 重量级锁

重量级锁依赖于操作系统的<mark style="background: #FF5582A6;">互斥量（mutex）</mark> 实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。

前面说到，每一个对象都可以当做一个锁，当多个线程同时请求某个对象锁时，对象锁会设置几种状态用来区分请求的线程：

```
Contention List：所有请求锁的线程将被首先放置到该竞争队列
Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List
Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set
OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck
Owner：获得锁的线程称为Owner
!Owner：释放锁的线程
```

当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个`ObjectWaiter`对象插入到Contention List的队列的队首，然后调用`park`函数挂起当前线程。

当线程释放锁时，会从Contention List或<mark style="background: #FF5582A6;">EntryList</mark>中挑选一个线程唤醒，被选中的线程叫做`Heir presumptive`即假定继承人，假定继承人被唤醒后会尝试获得锁，但`synchronized`是非公平的，所以假定继承人不一定能获得锁。这是因为对于重量级锁，线程先自旋尝试获得锁，这样做的目的是为了减少执行操作系统同步操作带来的开销。如果自旋不成功再进入等待队列。这对那些已经在等待队列中的线程来说，稍微显得不公平，还有一个不公平的地方是自旋线程可能会抢占了Ready线程的锁。

如果线程获得锁后调用`Object.wait`方法，则会将线程加入到<mark style="background: #FF5582A6;">WaitSet</mark>中，当被`Object.notify`唤醒后，会将线程从WaitSet移动到Contention List或EntryList中去。需要注意的是，当调用一个锁对象的`wait`或`notify`方法时，**如当前锁的状态是偏向锁或轻量级锁则会先膨胀成重量级锁**



## 锁的升级流程

每一个线程在准备获取共享资源时： 第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。

第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空。

第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的MarKword的内容修改为自己新建的记录空间的地址的方式竞争MarkWord。

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败 。

第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己


# CAS
volatile 保证了可见性和一定的有序性，但是不能保证原子性，如果要保证原子性，就要用到synchronized等方法，但是synchronized是<mark style="background: #FF5582A6;">悲观锁</mark>，对应的，乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，<mark style="background: #FF5582A6;">无需加锁</mark>也<mark style="background: #FF5582A6;">无需等待</mark>。而一旦多个线程<mark style="background: #FF5582A6;">发生冲突</mark>，乐观锁通常是使用一种称为<mark style="background: #FF5582A6;">CAS的技术</mark>来保证线程执行的安全性。

在 Java 编程中我们通常不会直接使用到 CAS，都是通过 JDK 封装好的并发工具类来间接使用的，这些并发工具类都在java.util.concurrent包中

**只能保证单个变量的原子性**

由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说**乐观锁天生免疫死锁**

乐观锁多用于“读多写少“的环境，避免频繁加锁影响性能；而悲观锁多用于”写多读少“的环境，避免频繁失败和重试影响性能。

> CAS: Compare and Swap
> 
> 比较并设置。用于在硬件层面上提供原子性操作。在 Intel 处理器中，比较并交换通过指令<mark style="background: #FF5582A6;">cmpxchg</mark>实现。 比较是否和给定的数值一致，如果一致则修改，不一致则不修改

3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。
> 内存地址V 也就是要更新的变量
> 旧的预期值A 也就是‘旧值’


CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。<mark style="background: #FF5582A6;">整个比较并替换的操作是一个原子操作</mark>

因为CAS是一种原子操作，它是一种<mark style="background: #FF5582A6;">系统原语</mark>，是一条CPU的原子指令，从CPU层面保证它的原子性

**当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作**



## Java实现CAS的原理 - Unsafe类

CAS是调用了Unsafe类的native方法，这些方法是c++写的，最终是通过`cmpxchg`指令来完成cas操作的，cas操作本身是不具备原子性的，也就是cas过程中是可以被其他线程打断的，但是通过`lock`指令，就能使`cmpxchg`指令变成一个原子的

Unsafe中对CAS的实现是C++写的，它的具体实现和操作系统、CPU都有关系。

Linux的X86下主要是通过`cmpxchgl`这个指令在CPU级完成CAS操作的，但在多处理器情况下必须使用`lock`指令加锁来完成。当然不同的操作系统和处理器的实现会有所不同

当然，Unsafe类里面还有其它方法用于不同的用途。比如支持线程挂起和恢复的`park`和`unpark`， LockSupport类底层就是调用了这两个方法。还有支持反射操作的`allocateInstance()`方法

## ABA问题
加版本号


## 循环时间长开销大

CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。

解决思路是让JVM支持处理器提供的**pause指令**。

pause指令能让自旋失败时cpu睡眠一小段时间再继续自旋，从而使得读操作的频率低很多,为解决内存顺序冲突而导致的CPU流水线重排的代价也会小很多。

## 只能保证一个共享变量的原子操作
这个问题有两种解决方案：

1. 使用JDK 1.5开始就提供的`AtomicReference`类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作；
2. 使用锁。锁内的临界区代码可以保证只有当前线程能操作



# AQS
## 简介
`AbstractQueuedSynchronizer`的简称，即`抽象队列同步器`

AQS是一个用来构建锁和同步器的框架，比如我们提到的ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。

当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器，只要子类实现它的几个`protected`方法就可以了


## AQS数据结构
AQS内部使用了一个volatile的变量state来作为资源的标识。同时定义了几个获取和改变state的protected方法，子类可以覆盖这些方法来实现自己的逻辑：

```java
getState()
setState()
compareAndSetState()
```


这三种操作均是原子操作，其中compareAndSetState的实现依赖于Unsafe的compareAndSwapInt()方法。

而AQS类本身实现的是一些排队和阻塞的机制，比如具体线程等待队列的维护（如获取资源失败入队/唤醒出队等）。它内部使用了一个先进先出（FIFO）的双端队列，并使用了两个指针head和tail用于标识队列的头部和尾部。其数据结构如图：
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230809042918.png)

但它并不是直接储存线程，而是储存拥有线程的Node节点


## 资源共享模式
资源有两种共享模式，或者说两种同步方式：

- <mark style="background: #D2B3FFA6;">独占模式</mark>（Exclusive）：资源是独占的，一次只能一个线程获取。如、、ReentrantLock。
- <mark style="background: #D2B3FFA6;">共享模式</mark>（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。

一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如`ReadWriteLock`。



# 线程池
为什么？
1. 创建/销毁线程需要<mark style="background: #FF5582A6;">消耗系统资源</mark>，线程池可以**复用已创建的线程**。
2. **控制并发的数量**。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）
3. **可以对线程做统一管理**。

## 原理：
Java中的线程池顶层接口是`Executor`接口，`ThreadPoolExecutor`是这个接口的实现类

ThreadPoolExecutor参数：
- **int corePoolSize**：该线程池中**核心线程数最大值**
- **int maximumPoolSize**：该线程池中**线程总数最大值** 。
- **long keepAliveTime**：**非核心线程闲置超时时长**。
- **TimeUnit unit**：keepAliveTime的单位。
- **BlockingQueue workQueue**：阻塞队列，维护着**等待执行的Runnable任务对象**。
    常用的几个阻塞队列：
    1. **LinkedBlockingQueue**
        链式阻塞队列，底层数据结构是链表，默认大小是`Integer.MAX_VALUE`，也可以指定大小。
    2. **ArrayBlockingQueue**
        数组阻塞队列，底层数据结构是数组，需要指定队列的大小。
    3. **SynchronousQueue**
        同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。
    4. **DelayQueue**
        延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。
- **ThreadFactory threadFactory**
    创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。
- **RejectedExecutionHandler handler**
    **拒绝处理策略**，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ：
    1. **ThreadPoolExecutor.AbortPolicy**：**默认拒绝处理策略**，丢弃任务并抛出RejectedExecutionException异常。
    2. **ThreadPoolExecutor.DiscardPolicy**：丢弃新来的任务，但是不抛出异常。
    3. **ThreadPoolExecutor.DiscardOldestPolicy**：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）。
    4. **ThreadPoolExecutor.CallerRunsPolicy**：由调用线程处理该任务。

## ThreadPoolExecutor的策略

线程池本身有一个调度线程，这个线程就是用于管理布控整个线程池里的各种任务和事务，例如创建线程、销毁线程、任务队列管理、线程队列管理等等。

故线程池也有自己的状态。`ThreadPoolExecutor`类中使用了一些`final int`常量变量来表示线程池的状态 ，分别为RUNNING、SHUTDOWN、STOP、TIDYING 、TERMINATED。

```java
// runState is stored in the high-order bits
private static final int RUNNING    = -1 << COUNT_BITS;
private static final int SHUTDOWN   =  0 << COUNT_BITS;
private static final int STOP       =  1 << COUNT_BITS;
private static final int TIDYING    =  2 << COUNT_BITS;
private static final int TERMINATED =  3 << COUNT_BITS;
```

- 线程池创建后处于**RUNNING**状态。
    
- 调用shutdown()方法后处于**SHUTDOWN**状态，线程池不能接受新的任务，清除一些空闲worker,不会等待阻塞队列的任务完成。
    
- 调用shutdownNow()方法后处于**STOP**状态，线程池不能接受新的任务，中断所有线程，阻塞队列中没有被执行的任务全部丢弃。此时，poolsize=0,阻塞队列的size也为0。
    
- 当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为**TIDYING**状态。接着会执行terminated()函数。
    
    > ThreadPoolExecutor中有一个控制状态的属性叫`ctl`，它是一个AtomicInteger类型的变量。线程池状态就是通过AtomicInteger类型的成员变量`ctl`来获取的。
    > 
    > 获取的`ctl`值传入`runStateOf`方法，与`~CAPACITY`位与运算(`CAPACITY`是低29位全1的int变量)。
    > 
    > `~CAPACITY`在这里相当于掩码，用来获取ctl的高3位，表示线程池状态；而另外的低29位用于表示工作线程数
    
- 线程池处在TIDYING状态时，**执行完terminated()方法之后**，就会由 **TIDYING -> TERMINATED**， 线程池被设置为TERMINATED状态。
    

## 线程池主要的任务处理流程

处理任务的核心方法是`execute`，我们看看 JDK 1.8 源码中`ThreadPoolExecutor`是如何处理线程任务的：

```java
// JDK 1.8 
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();   
    int c = ctl.get();
    // 1.当前线程数小于corePoolSize,则调用addWorker创建核心线程执行任务
    if (workerCountOf(c) < corePoolSize) {
       if (addWorker(command, true))
           return;
       c = ctl.get();
    }
    // 2.如果不小于corePoolSize，则将任务添加到workQueue队列。
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        // 2.1 如果isRunning返回false(状态检查)，则remove这个任务，然后执行拒绝策略。
        if (! isRunning(recheck) && remove(command))
            reject(command);
            // 2.2 线程池处于running状态，但是没有线程，则创建线程
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 3.如果放入workQueue失败，则创建非核心线程执行任务，
    // 如果这时创建非核心线程失败(当前线程总数不小于maximumPoolSize时)，就会执行拒绝策略。
    else if (!addWorker(command, false))
         reject(command);
}
```

`ctl.get()`是获取线程池状态，用`int`类型表示。第二步中，入队前进行了一次`isRunning`判断，入队之后，又进行了一次`isRunning`判断。

**为什么要二次检查线程池的状态?**

在多线程的环境下，线程池的状态是时刻发生变化的。很有可能刚获取线程池状态后线程池状态就改变了。判断是否将`command`加入`workqueue`是线程池之前的状态。倘若没有二次检查，万一线程池处于非**RUNNING**状态（在多线程环境下很有可能发生），那么`command`永远不会执行。

**总结一下处理流程**

1. 线程总数量 < corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 < corePoolSize时）。**注意，这一步需要获得全局锁。**
2. 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了**线程复用**）。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。**注意，这一步需要获得全局锁。**
4. 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。

整个过程如图所示：
![image.png](https://raw.githubusercontent.com/guchaolong/articleImgs/master/20230809051934.png)


## ThreadPoolExecutor如何做到线程复用的
我们知道，一个线程在创建的时候会指定一个线程任务，当执行完这个线程任务之后，线程自动销毁。但是线程池却可以复用线程，即一个线程执行完线程任务后不销毁，继续执行另外的线程任务。**那么，线程池如何做到线程复用呢？**

原来，ThreadPoolExecutor在创建线程时，会将线程封装成**工作线程worker**,并放入**工作线程组**中，然后这个worker反复从阻塞队列中拿任务去执行


## 4种常见线程池
### newCachedThreadPool

```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

`CacheThreadPool`的**运行流程**如下：

1. 提交任务进线程池。
2. 因为**corePoolSize**为0的关系，不创建核心线程，线程池最大为Integer.MAX_VALUE。
3. 尝试将任务添加到**SynchronousQueue**队列。
4. 如果SynchronousQueue入列成功，等待被当前运行的线程空闲后拉取执行。如果当前没有空闲线程，那么就创建一个非核心线程，然后从SynchronousQueue拉取任务并在当前线程执行。
5. 如果SynchronousQueue已有任务在等待，入列操作将会阻塞。

当需要执行很多**短时间**的任务时，CacheThreadPool的线程复用率比较高， 会显著的**提高性能**。而且线程60s后会回收，意味着即使没有任务进来，CacheThreadPool并不会占用很多资源。

最大线程数Integer.Max， N多线程，可能导致CPU 100%

### newFixedThreadPool

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
}
```

核心线程数量和总线程数量相等，都是传入的参数nThreads，所以只能创建核心线程，不能创建非核心线程。因为LinkedBlockingQueue的默认大小是Integer.MAX_VALUE，故如果核心线程空闲，则交给核心线程处理；如果核心线程不空闲，则入列等待，直到核心线程空闲。

newFixedThreadPool 定长，可控制线程最大并发数，超出的线程会在队列中等待
LinedBlockingQueue做队列，长度最大为Integer.Max， 可能导致内存溢出OOM

**与CachedThreadPool的区别**：

- 因为 corePoolSize == maximumPoolSize ，所以FixedThreadPool只会创建核心线程。 而CachedThreadPool因为corePoolSize=0，所以只会创建非核心线程。
- 在 getTask() 方法，如果队列里没有任务可取，线程会一直阻塞在 LinkedBlockingQueue.take() ，线程不会被回收。 CachedThreadPool会在60s后收回。
- 由于线程不会被回收，会一直卡在阻塞，所以**没有任务的情况下， FixedThreadPool占用资源更多**。
- 都几乎不会触发拒绝策略，但是原理不同。FixedThreadPool是因为阻塞队列可以很大（最大为Integer最大值），故几乎不会触发拒绝策略；CachedThreadPool是因为线程池很大（最大为Integer最大值），几乎不会导致线程数量大于最大线程数，故几乎不会触发拒绝策略。

### newSingleThreadExecutor

```java
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}
```

有且仅有一个核心线程（ corePoolSize == maximumPoolSize=1），使用了LinkedBlockingQueue（容量很大），所以，**不会创建非核心线程**。所有任务按照**先来先执行**的顺序执行。如果这个唯一的线程不空闲，那么新来的任务会存储在任务队列里等待执行。

单线程化，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
LinedBlockingQueue做队列，长度最大为Integer.Max， 可能导致内存溢出OOM

### newScheduledThreadPool

创建一个定长线程池，支持定时及周期性任务执行。

```java
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}

//ScheduledThreadPoolExecutor():
public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE,
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
          new DelayedWorkQueue());
}
```

四种常见的线程池基本够我们使用了，但是《阿里巴巴开发手册》不建议我们直接使用Executors类中的线程池，而是通过`ThreadPoolExecutor`的方式，这样的处理方式让写的同学需要更加明确线程池的运行规则，规避资源耗尽的风险。

但如果你及团队本身对线程池非常熟悉，又确定业务规模不会大到资源耗尽的程度（比如线程数量或任务队列长度可能达到Integer.MAX_VALUE）时，其实是可以使用JDK提供的这几个接口的，它能让我们的代码具有更强的可读性。